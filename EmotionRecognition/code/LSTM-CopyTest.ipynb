{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential, layers, callbacks\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.core.pylabtools import figsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of features data : 2\n",
      "length of Arousal labels data : 80 length of Valence labels data : 80\n"
     ]
    }
   ],
   "source": [
    "# for natural sorting\n",
    "import re\n",
    "\n",
    "def tryint(s):\n",
    "    try:\n",
    "        return int(s)\n",
    "    except:\n",
    "        return s\n",
    "def alphanum_key(s):\n",
    "    \"\"\" Turn a string into a list of string and number chunks.\n",
    "        \"z23a\" -> [\"z\", 23, \"a\"]\n",
    "    \"\"\"\n",
    "    return [ tryint(c) for c in re.split('([0-9]+)', s) ]\n",
    "def sort_nicely(l):\n",
    "    \"\"\" Sort the given list in the way that humans expect.\n",
    "    \"\"\"\n",
    "    l.sort(key=alphanum_key)\n",
    "    \n",
    "\n",
    "# load features data\n",
    "dir_path = \"/tmp/elias/emotion_recognition/features\"\n",
    "\n",
    "dir_list = os.listdir(dir_path)\n",
    "dir_list.sort()\n",
    "dir_list.pop(0)\n",
    "sort_nicely(dir_list)\n",
    "\n",
    "path = \"/tmp/elias/emotion_recognition/features/\"\n",
    "features_data = []\n",
    "count = 0\n",
    "for file in dir_list:\n",
    "    if count == 2:\n",
    "        break\n",
    "    data = np.loadtxt(path+file, delimiter=',',skiprows=1, usecols=range(1,19))\n",
    "    features_data.append(data)\n",
    "    count = count + 1\n",
    "\n",
    "print(\"length of features data :\", len(features_data))    \n",
    "\n",
    "\n",
    "# load labels data    \n",
    "dir_list_ = os.listdir(\"/tmp/elias/emotion_recognition/data\")\n",
    "dir_list_.sort()\n",
    "dir_list_ = dir_list_[:21]\n",
    "\n",
    "labels_Valence = []\n",
    "labels_Arousal = []\n",
    "\n",
    "count = 0\n",
    "for file in dir_list_:\n",
    "    if count == 2:\n",
    "        break\n",
    "    dat_file = '/tmp/elias/emotion_recognition/data/' + file\n",
    "    with open(dat_file, 'rb') as f:\n",
    "        Channel_data =pickle.load(f,encoding='latin1')\n",
    "    labels = Channel_data[\"labels\"]\n",
    "    for value in labels:\n",
    "        if value[0] < 5:\n",
    "            labels_Valence.append(0)\n",
    "        if value[0] >= 5:\n",
    "            labels_Valence.append(1)\n",
    "        if value[1] < 5:\n",
    "            labels_Arousal.append(0)\n",
    "        if value[1] >= 5:\n",
    "            labels_Arousal.append(1)\n",
    "    count = count + 1\n",
    "\n",
    "print(\"length of Arousal labels data :\", len(labels_Arousal), \"length of Valence labels data :\", len(labels_Valence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0vid_1_1.csv\n",
      "[[104.91666667 106.5          0.         ...   0.         100.\n",
      "    0.        ]\n",
      " [104.91666667 106.5          0.         ...   0.         100.\n",
      "    0.        ]\n",
      " [104.91666667 106.5          0.         ...   0.         100.\n",
      "    0.        ]\n",
      " ...\n",
      " [105.90909091 114.           1.         ...   0.         100.\n",
      "    0.        ]\n",
      " [105.90909091 114.           1.         ...   0.         100.\n",
      "    0.        ]\n",
      " [105.90909091 114.           1.         ...   0.         100.\n",
      "    0.        ]]\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# make sure you loaded data with no error\n",
    "print(dir_list[0])\n",
    "print(features_data[0])\n",
    "print(labels_Arousal[0])\n",
    "print(labels_Valence[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# data = pd.read_csv('/tmp/elias/emotion_recognition/features/0vid_1_1.csv', header = None)\n",
    "# import csv\n",
    "# file = open(\"/tmp/elias/emotion_recognition/features/0vid_1_1.csv\", \"r\")\n",
    "# csv_reader = csv.reader(file)\n",
    "\n",
    "# lists_from_csv = []\n",
    "# for row in csv_reader:\n",
    "#     lists_from_csv.append(row)\n",
    "# lists_from_csv.pop(0)\n",
    "# print(lists_from_csv)\n",
    "# print(len(lists_from_csv[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-06 15:15:16.433177: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-02-06 15:15:16.480998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-02-06 15:15:16.481286: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-02-06 15:15:16.483887: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-02-06 15:15:16.486144: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-02-06 15:15:16.486538: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-02-06 15:15:16.489256: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-02-06 15:15:16.490815: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-02-06 15:15:16.495198: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-02-06 15:15:16.496216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
      "2022-02-06 15:15:16.496871: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2022-02-06 15:15:16.524305: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2099990000 Hz\n",
      "2022-02-06 15:15:16.526653: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ba205e5860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-02-06 15:15:16.526694: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-02-06 15:15:16.527826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-02-06 15:15:16.527888: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-02-06 15:15:16.527924: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-02-06 15:15:16.527957: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-02-06 15:15:16.527990: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-02-06 15:15:16.528024: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-02-06 15:15:16.528077: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-02-06 15:15:16.528134: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-02-06 15:15:16.530007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
      "2022-02-06 15:15:16.530097: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-02-06 15:15:16.712742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-02-06 15:15:16.712777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
      "2022-02-06 15:15:16.712794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
      "2022-02-06 15:15:16.714845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4000 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5)\n",
      "2022-02-06 15:15:16.717136: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ba2003e3e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-02-06 15:15:16.717157: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 2 GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4000)]) # limit in megabytes\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test\n",
    "- what we have to do for this\n",
    " - 동영상 기준? ㅁ\n",
    " - 샘플 기준?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# train 80%, test 20%\n",
    "train_data = features_data[:2]\n",
    "test_data = features_data[672:]\n",
    "train_data_Vlabels = labels_Valence[:2]\n",
    "train_data_Alabels = labels_Arousal[:2]\n",
    "test_data_Vlabels = labels_Valence[672:]\n",
    "test_data_Alabels = labels_Arousal[672:]\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[104.91666667 106.5          0.         ...   0.         100.\n",
      "     0.        ]\n",
      "  [104.91666667 106.5          0.         ...   0.         100.\n",
      "     0.        ]\n",
      "  [104.91666667 106.5          0.         ...   0.         100.\n",
      "     0.        ]\n",
      "  ...\n",
      "  [105.90909091 114.           1.         ...   0.         100.\n",
      "     0.        ]\n",
      "  [105.90909091 114.           1.         ...   0.         100.\n",
      "     0.        ]\n",
      "  [105.90909091 114.           1.         ...   0.         100.\n",
      "     0.        ]]\n",
      "\n",
      " [[102.58333333 111.5          0.         ...   0.         100.\n",
      "     0.        ]\n",
      "  [102.58333333 111.5          0.         ...   0.         100.\n",
      "     0.        ]\n",
      "  [102.58333333 111.5          0.         ...   0.         100.\n",
      "     0.        ]\n",
      "  ...\n",
      "  [109.27272727 109.           0.         ...   0.         100.\n",
      "     0.        ]\n",
      "  [109.27272727 109.           0.         ...   0.         100.\n",
      "     0.        ]\n",
      "  [109.27272727 109.           0.         ...   0.         100.\n",
      "     0.        ]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 6400, 18)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_data = np.array(train_data)\n",
    "x_test_data = np.array(test_data)\n",
    "y_train_data = np.array(train_data_Vlabels)\n",
    "x_train_data.shape , y_train_data.shape\n",
    "print(x_train_data)\n",
    "\n",
    "# normalize data\n",
    "nsamples, nx, ny = x_train_data.shape\n",
    "train_dataset = x_train_data.reshape((nsamples,nx*ny))\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_train_data = scaler.fit_transform(train_dataset)\n",
    "\n",
    "###\n",
    "# X_train = x_train_data.reshape((x_train_data.shape[0], x_train_data.shape[1], 18))\n",
    "X_train = x_train_data.reshape((x_train_data.shape[0], 6400, 18))\n",
    "Y_train = y_train_data.reshape((y_train_data.shape[0], 1))\n",
    "# array([[a],[b],[c]...])\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build RNN, LSTM, GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Hyperparameters of the model\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6400, 18)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = Sequential()\n",
    "# model.add(GRU(units=64, activation='relu', input_shape=X_train[0].shape))\n",
    "model.add(GRU(units=64, activation='relu', input_shape=(6400,18),return_sequences=True))\n",
    "model.add(GRU(units=128, return_sequences = True))\n",
    "model.add(GRU(units=128, return_sequences =True))\n",
    "model.add(GRU(units=256))\n",
    "\n",
    "## gotta add dropout!\n",
    "# model.add(GRU(units=128, return_sequences=True, return_state=True,dropout=0.2))\n",
    "\n",
    "# Dense net\n",
    "model.add(Dense(256))\n",
    "# model.dropout(0.2)\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer=Adam(lr=learning_rate),metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "hist=model.fit(X_train,Y_train,epochs=epochs,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru (GRU)                    (None, 6400, 64)          16128     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 6400, 128)         74496     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 256)               296448    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 494,081\n",
      "Trainable params: 494,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(GRU(units=64, activation='relu', input_shape=(6400,18), return_sequences=True))\n",
    "model1.add(GRU(units=128, return_sequences=True))\n",
    "# model1.add(GRU(units=256, return_sequences=True))\n",
    "model1.add(GRU(units=256))\n",
    "\n",
    "## gotta add dropout!\n",
    "# model.add(GRU(units=128, return_sequences=True, return_state=True,dropout=0.2))\n",
    "\n",
    "# Dense net\n",
    "model1.add(Dense(256))\n",
    "model1.add(Dense(128))\n",
    "model1.add(Dense(64))\n",
    "model1.add(Dense(1))\n",
    "\n",
    "model1.compile(loss='binary_crossentropy',optimizer=Adam(lr=learning_rate),metrics=['mae'])\n",
    "# model1.compile(loss='binary_crossentropy',optimizer=Adam(lr=learning_rate),metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-06 15:15:20.391492: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-02-06 15:15:22.304784: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 15s 7s/sample - loss: 9.1292 - mae: 0.9827\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 11s 5s/sample - loss: 0.0000e+00 - mae: 8.6050\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 11s 5s/sample - loss: 0.0000e+00 - mae: 17.5170\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 11s 6s/sample - loss: 0.0000e+00 - mae: 25.0699\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 11s 6s/sample\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_829054/1932930848.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/sselab/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/home/sselab/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sselab/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sselab/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sselab/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sselab/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sselab/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sselab/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sselab/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sselab/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/home/sselab/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist=model1.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    RepeatVector(X_train.shape[1]), # replicates features from outputs (30 times)\n",
    "    LSTM(128, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    # Time distributed layer to get an output with right shape\n",
    "    TimeDistributed(Dense(X_train.shape[2]))\n",
    "])\n",
    "model.compile(loss='binary_clas', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model3 = Sequential([\n",
    "    LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    RepeatVector(X_train.shape[1]), # replicates features from outputs (30 times)\n",
    "    LSTM(128, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    # Time distributed layer to get an output with right shape\n",
    "    Dense(64),\n",
    "    Dense(1)\n",
    "])\n",
    "model3.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "hist=model3.fit(X_train,Y_train,epochs=epochs,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "inputs = keras.Input(shape=(6400,18))\n",
    "model = GRU(units=64,return_sequences=True,activation='relu')(inputs)\n",
    "model = GRU(units=128,return_sequences=True,activation='relu')(model)\n",
    "model = GRU(units=256,return_sequences=True,activation='relu')(model)\n",
    "model = GRU(units=128,activation='relu')(model)\n",
    "model = layers.Dense(64,activation='relu')(model)\n",
    "outputs = layers.Dense(1,activation='sigmoid')(model)\n",
    "\n",
    "model1 = keras.Model(inputs,outputs)\n",
    "model1.summary()\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## bidirectional\n",
    "model1 = Sequential([\n",
    "Bidirectional(layers.LSTM(units=100,activation='relu', return_sequences=True, return_state=True, input_shape=(1, 50))),\n",
    "Bidirectional(layers.LSTM(units=100,activation='relu', return_sequences=True, return_state=True)),\n",
    "Bidirectional(layers.LSTM(units=100,activation='relu', return_sequences=True, return_state=False)),\n",
    "Dense(units=100,activation='relu'),\n",
    "Dropout(0.1),\n",
    "Dense(units=100,activation='relu'),\n",
    "Dense(1)\n",
    "])\n",
    "\n",
    "##\n",
    "# model = Sequential()\n",
    "# # model.add(GRU(units=64, activation='relu', input_shape=X_train[0].shape))\n",
    "# model.add(GRU(units=64, activation='relu', input_shape=(672,18)))\n",
    "# model.add(GRU(units=128, return_sequences = True, return_state = True))\n",
    "# # model.add(GRU(units=128, return_sequences =True, return_state=True, statefull=True))\n",
    "# model.add(GRU(units=128))\n",
    "\n",
    "\n",
    "# ## gotta add dropout!\n",
    "# # model.add(GRU(units=128, return_sequences=True, return_state=True,dropout=0.2))\n",
    "\n",
    "# # Dense net\n",
    "# # model.add(Dense(128))\n",
    "# # model.add(Dense(256))\n",
    "# # model.add(Dense(512))\n",
    "# # model.add(Dense(1024))\n",
    "# # model.add(Dense(512))\n",
    "# model.add(Dense(128))\n",
    "# model.add(Dense(64))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "model1.compile(loss='binary_crossentropy',optimizer=Adam(lr=learning_rate),metrics=['mae'])\n",
    "history = model1.fit(X_train,Y_train, epochs=epochs,validation_split=0.1)\n",
    "model1.evaluate(test_input,test_output)\n",
    "# model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
