{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa8fdd3b-6481-4e25-a7f0-8d40f98fbe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neurokit2 as nk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "from scipy.signal import find_peaks\n",
    "from scipy import signal\n",
    "from scipy.integrate import trapz\n",
    "from scipy.interpolate import interp1d\n",
    "import seaborn as sns\n",
    "import heartpy as hp\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', np.RankWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1819f408-58a3-4c1c-a8ad-79d57f1b0bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_performance(history, path='./', filename=''):\n",
    "    epoch = list(range(0,len(history.history['loss'])))\n",
    "    \n",
    "    fig, (his_accuracy, his_loss) = plt.subplots(nrows=2,ncols=1,figsize=(10,8),sharex=True)\n",
    "    his_loss.plot(epoch, history.history['loss'], label='Training loss')\n",
    "    his_loss.plot(epoch, history.history['val_loss'], label='Validation loss')\n",
    "    his_loss.set_xlabel(\"Epochs\", fontsize=14)\n",
    "    his_loss.set_ylabel(\"Loss\", fontsize=14)\n",
    "    his_loss.set_title(\"Loss\", fontsize=14)\n",
    "    his_loss.legend(loc='best')\n",
    "    \n",
    "    his_accuracy.plot(epoch, history.history['accuracy'], label='Training accuracy')\n",
    "    his_accuracy.plot(epoch, history.history['val_accuracy'], label='Validation accuracy')\n",
    "    his_accuracy.set_xlabel(\"Epochs\", fontsize=14)\n",
    "    his_accuracy.set_ylabel(\"Accuracy\", fontsize=14)\n",
    "    his_accuracy.set_title(\"Accuracy\", fontsize=14)\n",
    "    his_accuracy.legend(loc='best')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    if filename == '':\n",
    "        plt.savefig(f'{path}/performance.png', bbox_inches='tight')\n",
    "    else:\n",
    "        plt.savefig(f'{path}/{filename}.png', bbox_inches='tight')\n",
    "        \n",
    "def preprocessing(PPG_data):\n",
    "    index = 0\n",
    "    x = list(range(0,len(PPG_data[0])))\n",
    "    for PPG in PPG_data:\n",
    "        poly = np.polyfit(x, PPG, deg=50)\n",
    "        polied = np.polyval(poly, x)\n",
    "        detrended = PPG - polied\n",
    "        PPG_data[index] = detrended\n",
    "        index += 1\n",
    "        \n",
    "        \n",
    "    return PPG_data\n",
    "    \n",
    "def get_peaks(ppg_processed):\n",
    "    diff_sig_2 = np.diff(ppg_processed) ## do\n",
    "    peaks_2, _ = find_peaks(diff_sig_2, distance=100*(30/60), prominence=0.01)\n",
    "    result = []\n",
    "    peaks = []\n",
    "    for i in range(len(peaks_2)):\n",
    "        if diff_sig_2[peaks_2][i] > 40:\n",
    "            result.append(peaks_2[i])\n",
    "            peaks.append(diff_sig_2[peaks_2][i])\n",
    "            \n",
    "    return result, peaks, diff_sig_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e8687c6-c1f6-4879-b18d-983c95d5629c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s01.dat', 's02.dat', 's03.dat', 's04.dat', 's05.dat', 's07.dat', 's08.dat', 's09.dat', 's10.dat', 's11.dat', 's12.dat', 's13.dat', 's14.dat', 's15.dat', 's16.dat', 's17.dat', 's18.dat', 's19.dat', 's20.dat', 's21.dat', 's22.dat']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(840, 7680)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_list_ = os.listdir(\"./data\")\n",
    "dir_list_.sort()\n",
    "count = 0\n",
    "dir_list = []\n",
    "for i in range(22):\n",
    "    dir_list.append(dir_list_[i])\n",
    "    \n",
    "#### pop unavailable data\n",
    "dir_list.pop(5)\n",
    "\n",
    "    \n",
    "print(dir_list)\n",
    "df_PPG = pd.DataFrame(columns=['participant','video_number','ppg','valence','arousal'])\n",
    "Valence_data = []\n",
    "Arousal_data = []\n",
    "PPG_data = []\n",
    "\n",
    "file_num = 0\n",
    "for file in dir_list:\n",
    "    dat_file = f'./data/{file}'\n",
    "    with open(dat_file, 'rb') as f:\n",
    "        Channel_data = pickle.load(f,encoding='latin1')\n",
    "    data = Channel_data[\"data\"]\n",
    "    labels = Channel_data[\"labels\"]\n",
    "    for video_num in range(40):\n",
    "        dataP = data[video_num,38]\n",
    "        dataP = dataP[384:]\n",
    "        \n",
    "        label = labels[video_num]\n",
    "        if label[0] < 5:\n",
    "            Valence = 0\n",
    "        if label[0] >= 5:\n",
    "            Valence = 1\n",
    "        if label[1] < 5:\n",
    "            Arousal = 0\n",
    "        if label[1] >= 5:\n",
    "            Arousal = 1\n",
    "        instance = [(file_num, video_num, dataP, Valence, Arousal)]\n",
    "        new_instance = pd.DataFrame(instance, columns=['participant','video_number','ppg','valence','arousal'])\n",
    "        df_PPG = pd.concat([df_PPG, new_instance], ignore_index = True)\n",
    "        PPG_data.append(dataP)\n",
    "        Valence_data.append(Valence)\n",
    "        Arousal_data.append(Arousal)\n",
    "    file_num += 1\n",
    "    \n",
    "PPG_shape = np.array(PPG_data)\n",
    "PPG_shape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "761b719f-bdae-4774-83c8-d98f0119a52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sselab/anaconda3/envs/EmotionRecognition/lib/python3.8/site-packages/numpy/lib/polynomial.py:627: RuntimeWarning: overflow encountered in multiply\n",
      "  scale = NX.sqrt((lhs*lhs).sum(axis=0))\n",
      "/home/sselab/anaconda3/envs/EmotionRecognition/lib/python3.8/site-packages/numpy/core/_methods.py:47: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
     ]
    }
   ],
   "source": [
    "PPG_data = df_PPG['ppg']\n",
    "\n",
    "preprocessed = preprocessing(PPG_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83c5852b-9475-4535-82e1-73db2d013dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(840, 7680, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate PPG data of each person to use min-max normalization method \n",
    "i = 1\n",
    "new_PPG = []\n",
    "tmp_PPG = np.empty(0)\n",
    "for PPG in preprocessed:\n",
    "    if i % 40 != 0:\n",
    "        tmp_PPG = np.concatenate([tmp_PPG, PPG])\n",
    "    else:\n",
    "        tmp_PPG = np.concatenate([tmp_PPG, PPG])\n",
    "        new_PPG.append(tmp_PPG)\n",
    "        tmp_PPG = np.empty(0)\n",
    "    i += 1\n",
    "    \n",
    "    \n",
    "# Normalize personal PPG data and Split into per video\n",
    "new_PPG = np.array(new_PPG)\n",
    "new_PPG.shape[0]\n",
    "new_PPG = new_PPG.reshape(new_PPG.shape[0],new_PPG.shape[1],1)\n",
    "\n",
    "normalized = []\n",
    "\n",
    "for PPG in new_PPG:\n",
    "    # Normalized personal PPG\n",
    "    scaler = MinMaxScaler()\n",
    "    norm = scaler.fit_transform(PPG) * 1000\n",
    "    \n",
    "    # Split into per video\n",
    "    for i in range(40):\n",
    "        norm_video = norm[i*7680 : i*7680+7680]\n",
    "        normalized.append(norm_video)\n",
    "\n",
    "normalized = np.array(normalized)\n",
    "normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07133d03-fefd-4fb8-88dd-123b26a62fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neurokit2.ppg.ppg_findpeaks as findpeaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "224f376d-94ab-4d9a-9193-74e324361cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented = []\n",
    "index = 0\n",
    "cal= 0\n",
    "\n",
    "index = 0\n",
    "for PPG in normalized:\n",
    "    \n",
    "    tmp = []\n",
    "    result = findpeaks(preprocessed[index], sampling_rate=128)\n",
    "    a = result['PPG_Peaks']\n",
    "    \n",
    "    for idx in a:\n",
    "        a = idx\n",
    "        if a > 70:\n",
    "            seg = PPG[a-70:a+70]\n",
    "            times = list(range(0,len(seg)))\n",
    "        else:\n",
    "            seg = PPG[0:a+70]\n",
    "            times = list(range(0,len(seg)))\n",
    "        if len(seg) == 140:\n",
    "            cal+=1\n",
    "            tmp.append(seg)\n",
    "\n",
    "    segmented.append(tmp)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e62cde3b-5265-409a-b4fa-69ef9a1b3ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840\n"
     ]
    }
   ],
   "source": [
    "# for seg in segmented:\n",
    "#     if len(seg) > 55:\n",
    "#         print(len(seg))\n",
    "print(len(segmented))\n",
    "valence_data = []\n",
    "arousal_data = []\n",
    "\n",
    "index = 0\n",
    "seger = []\n",
    "for seg in segmented:\n",
    "    for i in seg:\n",
    "        valence_data.append(Valence_data[index])\n",
    "        arousal_data.append(Arousal_data[index])\n",
    "        seger.append(i)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c67d31bf-2bd7-45ec-9495-44f0eedd8371",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_num = 0\n",
    "for seg in segmented:\n",
    "    plt.figure(figsize=(70,35))\n",
    "    times = list(range(0,140))\n",
    "    \n",
    "    for PPG in seg:\n",
    "        plt.plot(times,PPG)\n",
    "    \n",
    "    plt.savefig(f'segmented_data1seconds/{int(vid_num/40)+1}_{vid_num%40}.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    vid_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90975ab8-493a-4302-8506-6f15075a3cac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
