{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential, layers, callbacks\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "import np_utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.core.pylabtools import figsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - load features data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for natural sorting\n",
    "import re\n",
    "\n",
    "def tryint(s):\n",
    "    try:\n",
    "        return int(s)\n",
    "    except:\n",
    "        return s\n",
    "def alphanum_key(s):\n",
    "    \"\"\" Turn a string into a list of string and number chunks.\n",
    "        \"z23a\" -> [\"z\", 23, \"a\"]\n",
    "    \"\"\"\n",
    "    return [ tryint(c) for c in re.split('([0-9]+)', s) ]\n",
    "def sort_nicely(l):\n",
    "    \"\"\" Sort the given list in the way that humans expect.\n",
    "    \"\"\"\n",
    "    l.sort(key=alphanum_key)\n",
    "    \n",
    "    \n",
    "dir_path = \"/tmp/elias/emotion_recognition/features\"\n",
    "\n",
    "dir_list = os.listdir(dir_path)\n",
    "dir_list.sort()\n",
    "dir_list.pop(0)\n",
    "sort_nicely(dir_list)\n",
    "\n",
    "dir_list = dir_list[:800]\n",
    "print(len(dir_list))\n",
    "\n",
    "path = \"/tmp/elias/emotion_recognition/features/\"\n",
    "features_data = []\n",
    "count = 0\n",
    "for file in dir_list:\n",
    "    data = np.loadtxt(path+file, delimiter=',',skiprows=1, usecols=range(1,13))\n",
    "    features_data.append(data)\n",
    "    print(count)\n",
    "    count +=1\n",
    "\n",
    "print(\"length of features data :\", len(features_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - load labels data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dir_list_ = os.listdir(\"/tmp/elias/emotion_recognition/data\")\n",
    "dir_list_.sort()\n",
    "dir_list_ = dir_list_[:20]\n",
    "\n",
    "labels_Arousal = []\n",
    "labels_Valence = []\n",
    "for file in dir_list_:\n",
    "    dat_file = '/tmp/elias/emotion_recognition/data/' + file\n",
    "    with open(dat_file, 'rb') as f:\n",
    "        Channel_data =pickle.load(f,encoding='latin1')\n",
    "    labels = Channel_data[\"labels\"]\n",
    "    for value in labels:\n",
    "        if value[0] < 5:\n",
    "            labels_Valence.append(0)\n",
    "        if value[0] >= 5:\n",
    "            labels_Valence.append(1)\n",
    "        if value[1] < 5:\n",
    "            labels_Arousal.append(0)\n",
    "        if value[1] >= 5:\n",
    "            labels_Arousal.append(1)\n",
    "\n",
    "print(\"length of Arousal labels data :\", len(labels_Arousal), \"length of Valence labels data :\", len(labels_Valence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list_ = os.listdir(\"/tmp/elias/emotion_recognition/data\")\n",
    "dir_list_.sort()\n",
    "dir_list_ = dir_list_[:20]\n",
    "label = []\n",
    "\n",
    "# for file in dir_list_:\n",
    "#     dat_file = '/tmp/elias/emotion_recognition/data/' + file\n",
    "#     with open(dat_file, 'rb') as f:\n",
    "#         Channel_data =pickle.load(f,encoding='latin1')\n",
    "#     labels = Channel_data[\"labels\"]\n",
    "#     for value in labels:\n",
    "#         if value[0] < 5:\n",
    "#             Valence=0\n",
    "#             if value[1] < 5:\n",
    "#                 Aroucal=0\n",
    "#                 tmp = [1,0,0,0]\n",
    "#             else:\n",
    "#                 Aroucal=1\n",
    "#                 tmp = [0,0,1,0]\n",
    "#         if value[0] >= 5:\n",
    "#             Valence=1\n",
    "#             if value[1] < 5:\n",
    "#                 Arousal=0\n",
    "#                 tmp = [0,1,0,0]\n",
    "#             else:\n",
    "#                 Aroucal=1\n",
    "#                 tmp = [0,0,0,1]\n",
    "#         label.append(tmp)\n",
    "\n",
    "for file in dir_list_:\n",
    "    dat_file = '/tmp/elias/emotion_recognition/data/' + file\n",
    "    with open(dat_file, 'rb') as f:\n",
    "        Channel_data =pickle.load(f,encoding='latin1')\n",
    "    labels = Channel_data[\"labels\"]\n",
    "    for value in labels:\n",
    "        if value[0] < 5:\n",
    "            if value[1] < 5:\n",
    "                label.append('0') # [0 0 0 0] V=0, A=0\n",
    "            else:\n",
    "                label.append('1') # [0 1 0 0] V=0, A=1\n",
    "        else:\n",
    "            if value[1] < 5:\n",
    "                label.append('2') # [0 0 1 0] V=1, A=0\n",
    "            else:\n",
    "                label.append('3') # [0 0 0 0] V=1, A=1\n",
    "                \n",
    "# print(\"length of Arousal labels data :\", len(labels_Arousal), \"length of Valence labels data :\", len(labels_Valence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# make sure you loaded data with no error\n",
    "print(dir_list[0])\n",
    "print(features_data[0])\n",
    "print(labels_Arousal[0])\n",
    "print(labels_Valence[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# data = pd.read_csv('/tmp/elias/emotion_recognition/features/0vid_1_1.csv', header = None)\n",
    "# import csv\n",
    "# file = open(\"/tmp/elias/emotion_recognition/features/0vid_1_1.csv\", \"r\")\n",
    "# csv_reader = csv.reader(file)\n",
    "\n",
    "# lists_from_csv = []\n",
    "# for row in csv_reader:\n",
    "#     lists_from_csv.append(row)\n",
    "# lists_from_csv.pop(0)\n",
    "# print(lists_from_csv)\n",
    "# print(len(lists_from_csv[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-09 02:08:16.327393: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-02-09 02:08:16.381150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-02-09 02:08:16.381612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-02-09 02:08:16.385044: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-02-09 02:08:16.387890: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-02-09 02:08:16.388352: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-02-09 02:08:16.390850: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-02-09 02:08:16.392230: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-02-09 02:08:16.397594: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-02-09 02:08:16.399011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
      "2022-02-09 02:08:16.400655: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2022-02-09 02:08:16.432280: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2099990000 Hz\n",
      "2022-02-09 02:08:16.435320: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559ebf74d460 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-02-09 02:08:16.435366: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-02-09 02:08:16.436901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-02-09 02:08:16.436992: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-02-09 02:08:16.437034: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-02-09 02:08:16.437068: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-02-09 02:08:16.437104: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-02-09 02:08:16.437193: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-02-09 02:08:16.437249: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-02-09 02:08:16.437285: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-02-09 02:08:16.439218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
      "2022-02-09 02:08:16.439282: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-02-09 02:08:16.669858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-02-09 02:08:16.669897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
      "2022-02-09 02:08:16.669907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
      "2022-02-09 02:08:16.671990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6000 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5)\n",
      "2022-02-09 02:08:16.674650: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559ec1418080 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-02-09 02:08:16.674672: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 2 GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=6000)]) # limit in megabytes\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test\n",
    "- what we have to do for this\n",
    " - 동영상 기준? ㅁ\n",
    " - 샘플 기준?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# train 80%, test 20%\n",
    "train_data = features_data[:672]\n",
    "test_data = features_data[672:]\n",
    "train_data_Vlabels = labels_Valence[:672]\n",
    "train_data_Alabels = labels_Arousal[:672]\n",
    "test_data_Vlabels = labels_Valence[672:]\n",
    "test_data_Alabels = labels_Arousal[672:]\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672\n",
      "128\n",
      "800\n",
      "672\n"
     ]
    }
   ],
   "source": [
    "# train 80%, test 20%\n",
    "train_data = features_data[:672]\n",
    "test_data = features_data[672:]\n",
    "train_data_labels = label[:672]\n",
    "test_data_labels = label[672:]\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "print(len(label))\n",
    "print(len(train_data_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set train and test data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_train_data = np.array(train_data)\n",
    "y_train_data = np.array(train_data_Vlabels)\n",
    "x_test_data = np.array(test_data)\n",
    "y_test_data = np.array(test_data_Vlabels)\n",
    "print(x_train_data.shape , y_train_data.shape)\n",
    "\n",
    "# normalize data\n",
    "Train_nsamples, Train_nx, Train_ny = x_train_data.shape\n",
    "train_dataset = x_train_data.reshape((Train_nsamples,Train_nx*Train_ny))\n",
    "Test_nsamples, Test_nx, Test_ny = x_test_data.shape\n",
    "test_dataset = x_test_data.reshape((Test_nsamples,Test_nx*Test_ny))\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_train_data = scaler.fit_transform(train_dataset)\n",
    "x_test_data = scaler.fit_transform(test_dataset)\n",
    "\n",
    "###\n",
    "# X_train = x_train_data.reshape((x_train_data.shape[0], x_train_data.shape[1], 18))\n",
    "X_train = x_train_data.reshape((Train_nsamples, Train_nx, Train_ny))\n",
    "X_test = x_test_data.reshape((Test_nsamples, Test_nx, Test_ny))\n",
    "Y_train = y_train_data.reshape((y_train_data.shape[0], 1))\n",
    "Y_test = y_test_data.reshape((y_test_data.shape[0], 1))\n",
    "# array([[a],[b],[c]...])\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(672, 6337, 12)\n",
      "(128, 6337, 12)\n",
      "(672, 4)\n"
     ]
    }
   ],
   "source": [
    "x_train_data = np.array(train_data)\n",
    "y_train_data = np.array(train_data_labels)\n",
    "x_test_data = np.array(test_data)\n",
    "y_test_data = np.array(test_data_labels)\n",
    "x_train_data.shape , y_train_data.shape\n",
    "\n",
    "# normalize data\n",
    "Train_nsamples, Train_nx, Train_ny = x_train_data.shape\n",
    "train_dataset = x_train_data.reshape((Train_nsamples,Train_nx*Train_ny))\n",
    "Test_nsamples, Test_nx, Test_ny = x_test_data.shape\n",
    "test_dataset = x_test_data.reshape((Test_nsamples,Test_nx*Test_ny))\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_train_data = scaler.fit_transform(train_dataset)\n",
    "x_test_data = scaler.fit_transform(test_dataset)\n",
    "\n",
    "###\n",
    "X_train = x_train_data.reshape((Train_nsamples, Train_nx, Train_ny))\n",
    "X_test = x_test_data.reshape((Test_nsamples, Test_nx, Test_ny))\n",
    "Y_train = to_categorical(np.reshape(y_train_data,(len(y_train_data),1)))\n",
    "Y_test = to_categorical(np.reshape(y_test_data,(len(y_test_data),1)))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build RNN, LSTM, GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Hyperparameters of the model\n",
    "learning_rate = 0.001\n",
    "epochs = 200\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6337, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(128,\n",
    "                             dropout=0.25,\n",
    "                             recurrent_dropout=0.25,\n",
    "                             return_sequences=True,\n",
    "                             input_shape=X_train[0].shape)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Bidirectional(LSTM(256,\n",
    "                             dropout=0.25,\n",
    "                             recurrent_dropout=0.25,\n",
    "                             return_sequences=False)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=64,\n",
    "#                     validation_split=0.2,\n",
    "                    validation_data=(X_test, Y_test),\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# one GRU layers with three dense layers-> IT WORKS !\n",
    "model = Sequential()\n",
    "model.add(GRU(units=128,\n",
    "              dropout=0.25,\n",
    "              recurrent_dropout=0.25,\n",
    "              return_sequences=False,\n",
    "              input_shape=X_train[0].shape))\n",
    "\n",
    "# Dense net\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# two GRU layers with four dense layers-> IT WORKS !\n",
    "model = Sequential()\n",
    "model.add(GRU(units=128,\n",
    "              dropout=0.25,\n",
    "              recurrent_dropout=0.25,\n",
    "              return_sequences=True,\n",
    "              input_shape=X_train[0].shape))\n",
    "\n",
    "# model.add(GRU(units=128,\n",
    "#               dropout=0.25,\n",
    "#               recurrent_dropout=0.25,\n",
    "#               return_sequences =True))\n",
    "\n",
    "model.add(GRU(units=256,\n",
    "              return_sequences =False))\n",
    "\n",
    "# Dense net\n",
    "# model.add(Dense(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# two GRU layers with five dense layers-> IT WORKS !\n",
    "model = Sequential()\n",
    "model.add(GRU(units=128,\n",
    "              dropout=0.25,\n",
    "              recurrent_dropout=0.25,\n",
    "              return_sequences=True,\n",
    "              input_shape=X_train[0].shape))\n",
    "\n",
    "model.add(GRU(units=256,\n",
    "              return_sequences =False))\n",
    "\n",
    "## gotta add dropout!\n",
    "\n",
    "# Dense net\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " been# three GRU layers -> It doesn't work...\n",
    "model = Sequential()\n",
    "model.add(GRU(units=64,\n",
    "              dropout=0.25,\n",
    "              recurrent_dropout=0.25,\n",
    "              return_sequences=True,\n",
    "              input_shape=X_train[0].shape))\n",
    "\n",
    "model.add(GRU(units=128,\n",
    "              dropout=0.25,\n",
    "              recurrent_dropout=0.25,\n",
    "              return_sequences =True))\n",
    "\n",
    "model.add(GRU(units=256,\n",
    "              return_sequences =False))\n",
    "\n",
    "## gotta add dropout!\n",
    "\n",
    "# Dense net\n",
    "# model.add(Dense(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " been# two bidirectional GRU layers -> it doesn't work..\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(GRU(units=128,\n",
    "                            dropout=0.25,\n",
    "                            recurrent_dropout=0.25,\n",
    "                            return_sequences=True,\n",
    "                            input_shape=X_train[0].shape)))\n",
    "\n",
    "# model.add(GRU(units=128,\n",
    "#               dropout=0.25,\n",
    "#               recurrent_dropout=0.25,\n",
    "#               return_sequences =True))\n",
    "\n",
    "model.add(Bidirectional(GRU(units=256,\n",
    "                            dropout=0.25,\n",
    "                            recurrent_dropout=0.25,\n",
    "                            return_sequences=False)))\n",
    "\n",
    "## gotta add dropout!\n",
    "\n",
    "# Dense net\n",
    "# model.add(Dense(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model1 = Sequential()\n",
    "# model1.add(GRU(units=64, activation='relu', input_shape=X_train[0].shape))\n",
    "model1.add(GRU(units=64, activation='relu', input_shape=(6400,18),return_sequences=True))\n",
    "# model1.add(GRU(units=128, return_sequences = True))\n",
    "# model1.add(GRU(units=128, return_sequences =True))\n",
    "model1.add(GRU(units=256))\n",
    "\n",
    "## gotta add dropout!\n",
    "# model.add(GRU(units=128, return_sequences=True, return_state=True,dropout=0.2))\n",
    "\n",
    "# Dense net\n",
    "model1.add(Dense(256))\n",
    "# model.dropout(0.2)\n",
    "model1.add(Dense(128))\n",
    "model1.add(Dense(64))\n",
    "model1.add(Dense(1))\n",
    "\n",
    "model1.compile(loss='binary_crossentropy',optimizer=Adam(lr=learning_rate),metrics=['mae'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "inputs = keras.Input(shape=(6400,18))\n",
    "model = GRU(units=64,return_sequences=True,activation='relu')(inputs)\n",
    "model = GRU(units=128,return_sequences=True,activation='relu')(model)\n",
    "model = GRU(units=256,return_sequences=True,activation='relu')(model)\n",
    "model = GRU(units=128,activation='relu')(model)\n",
    "model = layers.Dense(64,activation='relu')(model)\n",
    "outputs = layers.Dense(1,activation='sigmoid')(model)\n",
    "\n",
    "model1 = keras.Model(inputs,outputs)\n",
    "model1.summary()\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "hist=model1.fit(X_train,Y_train,epochs=epochs,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## bidirectional\n",
    "model1 = Sequential([\n",
    "Bidirectional(layers.LSTM(units=100,activation='relu', return_sequences=True, return_state=True, input_shape=(1, 50))),\n",
    "Bidirectional(layers.LSTM(units=100,activation='relu', return_sequences=True, return_state=True)),\n",
    "Bidirectional(layers.LSTM(units=100,activation='relu', return_sequences=True, return_state=False)),\n",
    "Dense(units=100,activation='relu'),\n",
    "Dropout(0.1),\n",
    "Dense(units=100,activation='relu'),\n",
    "Dense(1)\n",
    "])\n",
    "\n",
    "##\n",
    "# model = Sequential()\n",
    "# # model.add(GRU(units=64, activation='relu', input_shape=X_train[0].shape))\n",
    "# model.add(GRU(units=64, activation='relu', input_shape=(672,18)))\n",
    "# model.add(GRU(units=128, return_sequences = True, return_state = True))\n",
    "# # model.add(GRU(units=128, return_sequences =True, return_state=True, statefull=True))\n",
    "# model.add(GRU(units=128))\n",
    "\n",
    "\n",
    "# ## gotta add dropout!\n",
    "# # model.add(GRU(units=128, return_sequences=True, return_state=True,dropout=0.2))\n",
    "\n",
    "# # Dense net\n",
    "# # model.add(Dense(128))\n",
    "# # model.add(Dense(256))\n",
    "# # model.add(Dense(512))\n",
    "# # model.add(Dense(1024))\n",
    "# # model.add(Dense(512))\n",
    "# model.add(Dense(128))\n",
    "# model.add(Dense(64))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "model1.compile(loss='binary_crossentropy',optimizer=Adam(lr=learning_rate),metrics=['mae'])\n",
    "history = model1.fit(X_train,Y_train, epochs=epochs,validation_split=0.1)\n",
    "model1.evaluate(test_input,test_output)\n",
    "# model1.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "history=model.fit(X_train,\n",
    "                  Y_train,\n",
    "                  epochs=epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  validation_data=(X_test,Y_test),\n",
    "                  verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru (GRU)                    (None, 128)               54528     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 88,580\n",
      "Trainable params: 88,580\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# one GRU layers with three dense layers-> IT WORKS !\n",
    "model = Sequential()\n",
    "model.add(GRU(units=128,\n",
    "              dropout=0.25,\n",
    "              recurrent_dropout=0.25,\n",
    "              return_sequences=False,\n",
    "              input_shape=X_train[0].shape))\n",
    "\n",
    "# Dense net\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(loss='mse', optimizer=Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 672 samples, validate on 128 samples\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-09 02:11:36.452341: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/672 [==========>...................] - ETA: 1:40 - loss: 0.1879 - accuracy: 0.2344"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,\n",
    "                  Y_train,\n",
    "                  epochs=epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  validation_data=(X_test,Y_test),\n",
    "                  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
